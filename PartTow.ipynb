{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "source": [
    "<p align=\"left\">\n",
    "    <img src=\"logo.png\" alt=\"Logo\" width=\"128\" height=\"154\">\n",
    "</p>\n",
    "\n",
    "<h1 align=\"center\">MA660E, Lab Report</h1>\n",
    "<h3 align=\"center\">Sirajulhaq Wahaj</h3>\n",
    "<h3> Part Two: Statistics and inference </h3>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart Disease Dataset\n",
    "\n",
    "This dataset contains information about patients and various attributes related to heart disease, collected from Cleveland Clinic and made available on Kaggle. It includes both qualitative and quantitative variables, which are ideal for performing analyses such as descriptive statistics, confidence intervals, hypothesis testing, correlation analysis, and multiple linear regression.\n",
    "\n",
    "**Source**: [Kaggle - Heart Disease Data](https://www.kaggle.com/datasets/redwankarimsony/heart-disease-data/data)\n",
    "\n",
    "---\n",
    "\n",
    "## Variables\n",
    "\n",
    "### Quantitative Variables\n",
    "- **id**: Unique identifier for each patient\n",
    "- **age**: Age of the patient in years\n",
    "- **trestbps**: Resting blood pressure in mm Hg\n",
    "- **chol**: Serum cholesterol level in mg/dl\n",
    "- **thalch**: Maximum heart rate achieved\n",
    "- **oldpeak**: ST depression induced by exercise relative to rest\n",
    "- **ca**: Number of major vessels (0-3) colored by fluoroscopy\n",
    "- **num**: Diagnosis of heart disease (angiographic disease status), where `0` indicates no disease and `1-4` indicates presence of disease\n",
    "\n",
    "### Qualitative Variables\n",
    "- **sex**: Sex of the patient, either `Male` or `Female`\n",
    "- **dataset**: Source of the data, e.g., Cleveland\n",
    "- **cp**: Chest pain type, with categories `typical angina`, `asymptomatic`, `non-anginal`, or `atypical angina`\n",
    "- **fbs**: Fasting blood sugar > 120 mg/dl, represented as `TRUE` if true and `FALSE` otherwise\n",
    "- **restecg**: Resting electrocardiographic results, either `normal` or `lv hypertrophy` (left ventricular hypertrophy)\n",
    "- **exang**: Exercise-induced angina, with `TRUE` if present and `FALSE` otherwise\n",
    "- **slope**: Slope of the peak exercise ST segment, categorized as `upsloping`, `flat`, or `downsloping`\n",
    "- **thal**: Type of thalassemia, with values `normal`, `fixed defect`, or `reversable defect`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "##    Results Part.\n",
    "</div>\n",
    "\n",
    "### Question 1. Descriptive Statistics\n",
    "Perform descriptive statistics analysis for at least two qualitative and two quantitative variables.\n",
    "\n",
    "\n",
    "#### Solution\n",
    "\n",
    "Quantitative Descriptive Statistics:\n",
    "\n",
    "- The average age of participants is about 53.5 years, with ages ranging from 28 to 77 years.\n",
    "- For blood pressure, the average is 132, but it can range from 0 to 200.\n",
    "- Cholesterol levels have an average of 200, with values ranging from 0 to 603.\n",
    "- The thalium stress test results average around 138, with values between 60 and 202.\n",
    "- The oldpeak (which measures depression induced by exercise) averages at 0.85, but it can range from -2.6 to 6.2.\n",
    "\n",
    "Qualitative Descriptive Statistics:\n",
    "\n",
    "- Sex: The majority of participants are male (726), with fewer females (194).\n",
    "- Chest pain type: Most participants are classified as having asymptomatic chest pain (496), followed by non-anginal pain (204), atypical angina (174), and typical angina (46).\n",
    "- Dataset origin: Most cases come from Cleveland (304), followed by Hungary (293), VA Long Beach (200), and Switzerland (123).\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2. Confidence Intervals\n",
    "Calculate the confidence interval for one quantitative variable and the confidence interval for the difference between two groups.\n",
    "\n",
    "\n",
    "#### Solution:\n",
    "Confidence Interval for Mean Age (95.0%): 52.901 to 54.121 \n",
    "\n",
    "Confidence Interval for Difference in Cholesterol Levels (Male - Female) (95.0%): -66.383 to -37.290\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3. T-test or ANOVA\n",
    "    \n",
    "Conduct a T-test to check if there is a significant difference between two groups, or Perform an ANOVA to see if all groups have the same mean for a characteristic.\n",
    "\n",
    "#### Solution:\n",
    "ANOVA Results for Cholesterol Levels across Chest Pain Types:\n",
    "\n",
    "F-statistic: 7.5912\n",
    "\n",
    "P-value: 0.0001\n",
    "\n",
    "Result: Significant differences in cholesterol levels across chest pain types (p < 0.05).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4. Non-Parametric Test\n",
    "Conduct a non-parametric test for the same variable as in Exercise 3 and compare the conclusions with ANOVA results.\n",
    "\n",
    "#### Solution:\n",
    "\n",
    "Kruskal-Wallis Test:\n",
    "\n",
    "Statistic: 12.772943982536457, p-value: 0.005154264553910447\n",
    "\n",
    "Conclusion: There is a statistically significant difference in cholesterol levels among the chest pain types.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Correlation Analysis\n",
    "Identify the strongest correlations and any statistically insignificant relationships.\n",
    "\n",
    "#### Solution:\n",
    "\n",
    "![image.png](corr_analysis.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: 6. Multiple Linear Regression\n",
    "Perform a multiple linear regression analysis.\n",
    "\n",
    "In this multiple regression analysis, the goal is to understand how the dependent variable, num, is influenced by several independent variables: age, trestbps, thalch, oldpeak, sex, cp, fbs, restecg, exang, and chol. By examining these predictors together, we aim to see how well they explain changes in num and identify which factors have the most significant impact.\n",
    "\n",
    "\n",
    "#### Solution:\n",
    "\n",
    "The multiple regression analysis explains 40.4% of the variability in the dependent variable, num, as indicated by the R-squared value. Significant predictors include age, oldpeak, sex, cp, restecg, exang, and chol, which have a strong relationship with num. Variables like trestbps and fbs showed less impact on the outcome. The model was trained and tested using a 70-30 split, and evaluation metrics such as R-squared and Mean Squared Error were used to assess its performance. While the model performed reasonably well, the high condition number suggests potential multicollinearity among some predictors, warranting further investigation to ensure reliable results.\n",
    "\n",
    "![image.png](osl9.png)\n",
    "\n",
    "---\n",
    "![image.png](osl3.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "# Code Part\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import kruskal\n",
    "from scipy.stats import pearsonr\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# silient downcasting and warnnings \n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "data_set = pd.read_csv('heart_disease_uci.csv')\n",
    "null_values = data_set.isnull().sum()\n",
    "\n",
    "# Columns with null values\n",
    "quantitative_columns = ['trestbps', 'chol', 'thalch', 'oldpeak', 'ca', 'age', 'num']\n",
    "qualitative_columns = ['sex', 'cp', 'restecg', 'fbs', 'exang', 'slope', 'thal']\n",
    "\n",
    "\n",
    "# 1. Quantitative Columns: Fill missing values with the median\n",
    "data_cleaned = data_set.copy()\n",
    "for col in quantitative_columns:\n",
    "    if data_set[col].isnull().sum() > 0:\n",
    "        median_value = data_set[col].median()\n",
    "        data_cleaned[col] = data_set[col].fillna(median_value)\n",
    "\n",
    "# 2. Qualitative Columns: Fill missing values with the mode\n",
    "for col in qualitative_columns:\n",
    "    if data_set[col].isnull().sum() > 0:\n",
    "        mode_value = data_set[col].mode()[0]\n",
    "        data_cleaned[col] = data_set[col].fillna(mode_value).infer_objects()\n",
    "# Convert sex column to numeric\n",
    "data_cleaned['sex'] = data_cleaned['sex'].map({'Female': 0, 'Male': 1})\n",
    "data_cleaned['cp'] = data_cleaned['cp'].map({'typical angina': 0, 'atypical angina': 1, 'non-anginal': 2, 'asymptomatic': 3})\n",
    "data_cleaned['fbs'] = data_cleaned['fbs'].map({False: 0, True: 1})\n",
    "data_cleaned['exang'] = data_cleaned['exang'].map({False: 0, True: 1})\n",
    "data_cleaned['restecg'] = data_cleaned['restecg'].map({'normal': 0, 'abnormal': 1, 'lv hypertrophy': 2})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with null values:\n",
      "restecg: 179 null values\n"
     ]
    }
   ],
   "source": [
    "null_values = data_cleaned.isnull().sum()\n",
    "\n",
    "columns_with_null = null_values[null_values > 0]\n",
    "if len(columns_with_null) > 0:\n",
    "    print(\"Columns with null values:\")\n",
    "else:\n",
    "    print(\"No columns with null values.\")\n",
    "    \n",
    "for column, null_count in columns_with_null.items():\n",
    "    print(f\"{column}: {null_count} null values\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Two: 1. Descriptive Statistics\n",
    "Perform descriptive statistics analysis for at least two qualitative and two quantitative variables.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Quantitative Descriptive Statistics ====================\n",
      "\n",
      "Descriptive statistics for quantitative variables (age, trestbps, chol, thalch, oldpeak):\n",
      "\n",
      "This includes measures such as the mean, standard deviation, min, 25th percentile (Q1), median (50th percentile), 75th percentile (Q3), and max for each of these columns.\n",
      "              age    trestbps        chol      thalch     oldpeak\n",
      "count  920.000000  920.000000  920.000000  920.000000  920.000000\n",
      "mean    53.510870  131.995652  199.908696  137.692391    0.853261\n",
      "std      9.424685   18.451300  109.040171   25.145235    1.058049\n",
      "min     28.000000    0.000000    0.000000   60.000000   -2.600000\n",
      "25%     47.000000  120.000000  177.750000  120.000000    0.000000\n",
      "50%     54.000000  130.000000  223.000000  140.000000    0.500000\n",
      "75%     60.000000  140.000000  267.000000  156.000000    1.500000\n",
      "max     77.000000  200.000000  603.000000  202.000000    6.200000\n",
      "\n",
      "==================== Qualitative Descriptive Statistics ====================\n",
      "\n",
      "Frequency counts for qualitative variables (sex, cp, dataset):\n",
      "\n",
      "For the variable 'sex', the distribution is as follows:\n",
      "sex\n",
      "1    726\n",
      "0    194\n",
      "Name: count, dtype: int64\n",
      "\n",
      "For the variable 'cp', the distribution is as follows:\n",
      "cp\n",
      "3    496\n",
      "2    204\n",
      "1    174\n",
      "0     46\n",
      "Name: count, dtype: int64\n",
      "\n",
      "For the variable 'dataset', the distribution is as follows:\n",
      "dataset\n",
      "Cleveland        304\n",
      "Hungary          293\n",
      "VA Long Beach    200\n",
      "Switzerland      123\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Columns to analyze\n",
    "quantitative_columns = ['age', 'trestbps', 'chol', 'thalch', 'oldpeak']\n",
    "qualitative_columns = ['sex', 'cp', 'dataset']\n",
    "\n",
    "# Generate descriptive statistics for quantitative variables\n",
    "quantitative_stats = data_cleaned[quantitative_columns].describe()\n",
    "\n",
    "# Generate frequency counts for qualitative variables\n",
    "qualitative_stats = {col: data_cleaned[col].value_counts() for col in qualitative_columns}\n",
    "\n",
    "# Output results to console in a structured format\n",
    "\n",
    "# Quantitative Descriptive Statistics\n",
    "print(\"\\n==================== Quantitative Descriptive Statistics ====================\")\n",
    "print(f\"\\nDescriptive statistics for quantitative variables ({', '.join(quantitative_columns)}):\")\n",
    "print(\"\\nThis includes measures such as the mean, standard deviation, min, 25th percentile (Q1), median (50th percentile), 75th percentile (Q3), and max for each of these columns.\")\n",
    "print(quantitative_stats)\n",
    "\n",
    "# Qualitative Descriptive Statistics\n",
    "print(\"\\n==================== Qualitative Descriptive Statistics ====================\")\n",
    "print(f\"\\nFrequency counts for qualitative variables ({', '.join(qualitative_columns)}):\")\n",
    "for col, stats in qualitative_stats.items():\n",
    "    print(f\"\\nFor the variable '{col}', the distribution is as follows:\")\n",
    "    print(stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Two: 2. Confidence Intervals\n",
    "Calculate the confidence interval for one quantitative variable and the confidence interval for the difference between two groups.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval for Mean Age (95.0%): 52.901 to 54.121\n",
      "Confidence Interval for Difference in Cholesterol Levels (Male - Female) (95.0%): nan to nan\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Set confidence level\n",
    "confidence_level = 0.95\n",
    "\n",
    "# Confidence Interval for Mean Age\n",
    "def calculate_age_confidence_interval(data):\n",
    "    age_mean = data['age'].mean()\n",
    "    age_std = data['age'].std()\n",
    "    age_n = data['age'].count()\n",
    "    age_se = age_std / np.sqrt(age_n)\n",
    "    return stats.t.interval(confidence_level, df=age_n-1, loc=age_mean, scale=age_se)\n",
    "\n",
    "# Confidence Interval for Difference in Cholesterol Levels\n",
    "def calculate_cholesterol_difference_confidence_interval(data):\n",
    "    chol_male = data[data['sex'] == 'Male']['chol']\n",
    "    chol_female = data[data['sex'] == 'Female']['chol']\n",
    "    \n",
    "    chol_male_mean = chol_male.mean()\n",
    "    chol_female_mean = chol_female.mean()\n",
    "    chol_male_std = chol_male.std()\n",
    "    chol_female_std = chol_female.std()\n",
    "    \n",
    "    n_male = chol_male.count()\n",
    "    n_female = chol_female.count()\n",
    "    \n",
    "    se_diff = np.sqrt((chol_male_std**2 / n_male) + (chol_female_std**2 / n_female))\n",
    "    mean_diff = chol_male_mean - chol_female_mean\n",
    "    df_diff = min(n_male, n_female) - 1\n",
    "    \n",
    "    return stats.t.interval(confidence_level, df=df_diff, loc=mean_diff, scale=se_diff)\n",
    "\n",
    "# Calculate and print results\n",
    "age_ci = calculate_age_confidence_interval(data_cleaned)\n",
    "print(f\"Confidence Interval for Mean Age ({confidence_level*100}%): {age_ci[0]:.3f} to {age_ci[1]:.3f}\")\n",
    "\n",
    "chol_ci = calculate_cholesterol_difference_confidence_interval(data_cleaned)\n",
    "print(f\"Confidence Interval for Difference in Cholesterol Levels (Male - Female) ({confidence_level*100}%): {chol_ci[0]:.3f} to {chol_ci[1]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Two: 3. T-test or ANOVA\n",
    "    \n",
    "Conduct a T-test to check if there is a significant difference between two groups, or Perform an ANOVA to see if all groups have the same mean for a characteristic.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA Results for Cholesterol Levels across Chest Pain Types:\n",
      "F-statistic: 7.5912\n",
      "P-value: 0.0001\n",
      "Result: Significant differences in cholesterol levels across chest pain types (p < 0.05).\n"
     ]
    }
   ],
   "source": [
    "# Separate cholesterol levels by chest pain type (cp)\n",
    "cp_groups = []\n",
    "for cp in data_cleaned['cp'].unique():\n",
    "    # Filter cholesterol values for each unique chest pain type without dropping nulls\n",
    "    chol_values = data_cleaned[data_cleaned['cp'] == cp]['chol']\n",
    "    cp_groups.append(chol_values)\n",
    "    \n",
    "#cp_groups = [data_cleaned[data_cleaned['cp'] == cp]['chol'] for cp in data_cleaned['cp'].unique()]\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_stat, p_value = stats.f_oneway(*cp_groups)\n",
    "\n",
    "# Output the result\n",
    "print(\"ANOVA Results for Cholesterol Levels across Chest Pain Types:\")\n",
    "print(f\"F-statistic: {f_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "# Interpretation\n",
    "if p_value < 0.05:\n",
    "    print(\"Result: Significant differences in cholesterol levels across chest pain types (p < 0.05).\")\n",
    "else:\n",
    "    print(\"Result: No significant differences in cholesterol levels across chest pain types (p â‰¥ 0.05).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Two: 4. Non-Parametric Test\n",
    "Conduct a non-parametric test for the same variable as in Exercise 3 and compare the conclusions with ANOVA results.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal-Wallis Test:\n",
      "Statistic: 12.772943982536457, p-value: 0.005154264553910447\n",
      "Conclusion: There is a statistically significant difference in cholesterol levels among the chest pain types.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Conduct the Kruskal-Wallis test\n",
    "kruskal_stat, kruskal_p_value = kruskal(*cp_groups)\n",
    "\n",
    "# Output the result\n",
    "print(\"Kruskal-Wallis Test:\")\n",
    "print(f\"Statistic: {kruskal_stat}, p-value: {kruskal_p_value}\")\n",
    "\n",
    "# Interpretation based on p-value\n",
    "if kruskal_p_value < 0.05:\n",
    "    print(\"Conclusion: There is a statistically significant difference in cholesterol levels among the chest pain types.\")\n",
    "else:\n",
    "    print(\"Conclusion: No statistically significant difference in cholesterol levels among the chest pain types.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Two: 5. Correlation Analysis\n",
    "Identify the strongest correlations and any statistically insignificant relationships.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Matrix:\n",
      "               age  trestbps      chol    thalch   oldpeak\n",
      "age       1.000000  0.230784 -0.086010 -0.349715  0.233550\n",
      "trestbps  0.230784  1.000000  0.089484 -0.104747  0.161217\n",
      "chol     -0.086010  0.089484  1.000000  0.226047  0.047454\n",
      "thalch   -0.349715 -0.104747  0.226047  1.000000 -0.149401\n",
      "oldpeak   0.233550  0.161217  0.047454 -0.149401  1.000000\n",
      "\n",
      "Strongest Correlations (|correlation| > 0.5):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistically Insignificant Relationships (p > 0.05):\n",
      "chol and oldpeak: p-value = 0.1504\n",
      "oldpeak and chol: p-value = 0.1504\n"
     ]
    }
   ],
   "source": [
    "quantitative_columns = ['age', 'trestbps', 'chol', 'thalch', 'oldpeak']\n",
    "correlation_matrix = data_cleaned[quantitative_columns].corr()\n",
    "\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "#find the strongest correlations like |correlation| > 0.5\n",
    "\n",
    "strong_correlations = []\n",
    "for col1 in quantitative_columns:\n",
    "    for col2 in quantitative_columns:\n",
    "        if col1 != col2:\n",
    "            correlation = correlation_matrix.loc[col1, col2]\n",
    "            if abs(correlation) > 0.5:\n",
    "                strong_correlations.append((col1, col2, correlation))\n",
    "\n",
    "print(\"\\nStrongest Correlations (|correlation| > 0.5):\")\n",
    "for col1, col2, corr in strong_correlations:\n",
    "    print(f\"{col1} and {col2}: correlation = {corr:.2f}\")\n",
    "\n",
    "\n",
    "#Check statistically insignificant relationships (p > 0.05)\n",
    "insignificant_correlations = []\n",
    "for col1 in quantitative_columns:\n",
    "    for col2 in quantitative_columns:\n",
    "        if col1 != col2:\n",
    "            corr, p_value = pearsonr(data_cleaned[col1].dropna(), data_cleaned[col2].dropna())\n",
    "            if p_value > 0.05:\n",
    "                insignificant_correlations.append((col1, col2, p_value))\n",
    "\n",
    "print(\"\\nStatistically Insignificant Relationships (p > 0.05):\")\n",
    "for col1, col2, p_value in insignificant_correlations:\n",
    "    print(f\"{col1} and {col2}: p-value = {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Two: 6. Multiple Linear Regression\n",
    "Perform a multiple linear regression analysis.\n",
    "\n",
    "----\n",
    "In this multiple regression analysis, the goal is to understand how the dependent variable, num, is influenced by several independent variables: age, trestbps, thalch, oldpeak, sex, cp, fbs, restecg, exang, and chol. By examining these predictors together, we aim to see how well they explain changes in num and identify which factors have the most significant impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    num   R-squared:                       0.404\n",
      "Model:                            OLS   Adj. R-squared:                  0.396\n",
      "Method:                 Least Squares   F-statistic:                     49.57\n",
      "Date:                Mon, 09 Dec 2024   Prob (F-statistic):           1.47e-75\n",
      "Time:                        18:45:43   Log-Likelihood:                -937.76\n",
      "No. Observations:                 741   AIC:                             1898.\n",
      "Df Residuals:                     730   BIC:                             1948.\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0234      0.415     -0.056      0.955      -0.837       0.791\n",
      "age            0.0137      0.004      3.528      0.000       0.006       0.021\n",
      "trestbps       0.0012      0.002      0.633      0.527      -0.002       0.005\n",
      "thalch        -0.0052      0.001     -3.461      0.001      -0.008      -0.002\n",
      "oldpeak        0.3184      0.034      9.246      0.000       0.251       0.386\n",
      "sex            0.3327      0.079      4.209      0.000       0.178       0.488\n",
      "cp             0.2272      0.038      5.913      0.000       0.152       0.303\n",
      "fbs            0.0893      0.099      0.904      0.366      -0.105       0.283\n",
      "restecg        0.1321      0.039      3.417      0.001       0.056       0.208\n",
      "exang          0.1960      0.080      2.437      0.015       0.038       0.354\n",
      "chol          -0.0019      0.000     -5.794      0.000      -0.002      -0.001\n",
      "==============================================================================\n",
      "Omnibus:                       81.790   Durbin-Watson:                   1.917\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              109.623\n",
      "Skew:                           0.846   Prob(JB):                     1.57e-24\n",
      "Kurtosis:                       3.831   Cond. No.                     3.91e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.91e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Define the target and predictor variables\n",
    "#['age', 'sex', 'cp', 'trestbps', 'fbs', 'restecg', 'thalch', 'exang']\n",
    "X = data_cleaned[['age', 'trestbps', 'thalch', 'oldpeak', 'sex', 'cp', 'fbs', 'restecg', 'exang', 'chol']]  # Predictor variables\n",
    "y = data_cleaned['num']  # Target variable\n",
    "\n",
    "# Drop any rows with missing values in X or y\n",
    "X = X.dropna()\n",
    "y = y.loc[X.index]  # Keep y aligned with the non-null X\n",
    "\n",
    "# Add a constant to X to account for the intercept\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Output the summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.382249792102602\n",
      "Mean Squared Error: 0.8061845802675568\n",
      "Coefficients: [ 1.47960179e-02 -2.11397611e-04 -5.45987756e-03  3.20096038e-01\n",
      "  3.90277773e-01  2.32907223e-01  2.77445628e-02  1.30664271e-01\n",
      "  1.55654860e-01 -1.84402977e-03]\n",
      "Intercept: 0.08562560509436445\n"
     ]
    }
   ],
   "source": [
    "data_cleaned = data_cleaned.dropna(subset=['age', 'trestbps', 'thalch', 'oldpeak', 'sex', 'cp', 'fbs', 'restecg', 'exang', 'chol', 'num'])\n",
    "X = data_cleaned[['age', 'trestbps', 'thalch', 'oldpeak', 'sex', 'cp', 'fbs', 'restecg', 'exang', 'chol']]\n",
    "y = data_cleaned['num']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"R-squared:\", r2_score(y_test, y_pred))\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
