{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "source": [
    "<p align=\"left\">\n",
    "    <img src=\"logo.png\" alt=\"Logo\" width=\"128\" height=\"154\">\n",
    "</p>\n",
    "\n",
    "<h1 align=\"center\">MA660E, Lab Report</h1>\n",
    "<h3 align=\"center\">Sirajulhaq Wahaj</h3>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart Disease Dataset\n",
    "\n",
    "## Overview\n",
    "This dataset contains information about patients and various attributes related to heart disease, collected from Cleveland Clinic and made available on Kaggle. It includes both qualitative and quantitative variables, which are ideal for performing analyses such as descriptive statistics, confidence intervals, hypothesis testing, correlation analysis, and multiple linear regression.\n",
    "\n",
    "**Source**: [Kaggle - Heart Disease Data](https://www.kaggle.com/datasets/redwankarimsony/heart-disease-data/data)\n",
    "\n",
    "---\n",
    "\n",
    "## Variables\n",
    "\n",
    "### Quantitative Variables\n",
    "- **id**: Unique identifier for each patient\n",
    "- **age**: Age of the patient in years\n",
    "- **trestbps**: Resting blood pressure in mm Hg\n",
    "- **chol**: Serum cholesterol level in mg/dl\n",
    "- **thalch**: Maximum heart rate achieved\n",
    "- **oldpeak**: ST depression induced by exercise relative to rest\n",
    "- **ca**: Number of major vessels (0-3) colored by fluoroscopy\n",
    "- **num**: Diagnosis of heart disease (angiographic disease status), where `0` indicates no disease and `1-4` indicates presence of disease\n",
    "\n",
    "### Qualitative Variables\n",
    "- **sex**: Sex of the patient, either `Male` or `Female`\n",
    "- **dataset**: Source of the data, e.g., Cleveland\n",
    "- **cp**: Chest pain type, with categories `typical angina`, `asymptomatic`, `non-anginal`, or `atypical angina`\n",
    "- **fbs**: Fasting blood sugar > 120 mg/dl, represented as `TRUE` if true and `FALSE` otherwise\n",
    "- **restecg**: Resting electrocardiographic results, either `normal` or `lv hypertrophy` (left ventricular hypertrophy)\n",
    "- **exang**: Exercise-induced angina, with `TRUE` if present and `FALSE` otherwise\n",
    "- **slope**: Slope of the peak exercise ST segment, categorized as `upsloping`, `flat`, or `downsloping`\n",
    "- **thal**: Type of thalassemia, with values `normal`, `fixed defect`, or `reversable defect`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Two: 1. Descriptive Statistics\n",
    "#### Task\n",
    "Perform descriptive statistics analysis for at least two qualitative and two quantitative variables.\n",
    "\n",
    "---\n",
    "\n",
    "#### Solution\n",
    "\n",
    "- **Confidence Interval for Job Satisfaction (Satis):**  (10.06, 11.61)\n",
    "\n",
    "- **Confidence Interval for the Difference in Job Satisfaction between Men and Women:**  (-1.38, 1.85)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import kruskal\n",
    "from scipy.stats import pearsonr\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trestbps: 59 null values\n",
      "chol: 30 null values\n",
      "fbs: 90 null values\n",
      "restecg: 2 null values\n",
      "thalch: 55 null values\n",
      "exang: 55 null values\n",
      "oldpeak: 62 null values\n",
      "slope: 309 null values\n",
      "ca: 611 null values\n",
      "thal: 486 null values\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 920 entries, 0 to 919\n",
      "Data columns (total 16 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   id        920 non-null    int64  \n",
      " 1   age       920 non-null    int64  \n",
      " 2   sex       920 non-null    object \n",
      " 3   dataset   920 non-null    object \n",
      " 4   cp        920 non-null    object \n",
      " 5   trestbps  861 non-null    float64\n",
      " 6   chol      890 non-null    float64\n",
      " 7   fbs       830 non-null    object \n",
      " 8   restecg   918 non-null    object \n",
      " 9   thalch    865 non-null    float64\n",
      " 10  exang     865 non-null    object \n",
      " 11  oldpeak   858 non-null    float64\n",
      " 12  slope     611 non-null    object \n",
      " 13  ca        309 non-null    float64\n",
      " 14  thal      434 non-null    object \n",
      " 15  num       920 non-null    int64  \n",
      "dtypes: float64(5), int64(3), object(8)\n",
      "memory usage: 115.1+ KB\n",
      "None\n",
      "               id         age    trestbps        chol      thalch     oldpeak  \\\n",
      "count  920.000000  920.000000  861.000000  890.000000  865.000000  858.000000   \n",
      "mean   460.500000   53.510870  132.132404  199.130337  137.545665    0.878788   \n",
      "std    265.725422    9.424685   19.066070  110.780810   25.926276    1.091226   \n",
      "min      1.000000   28.000000    0.000000    0.000000   60.000000   -2.600000   \n",
      "25%    230.750000   47.000000  120.000000  175.000000  120.000000    0.000000   \n",
      "50%    460.500000   54.000000  130.000000  223.000000  140.000000    0.500000   \n",
      "75%    690.250000   60.000000  140.000000  268.000000  157.000000    1.500000   \n",
      "max    920.000000   77.000000  200.000000  603.000000  202.000000    6.200000   \n",
      "\n",
      "               ca         num  \n",
      "count  309.000000  920.000000  \n",
      "mean     0.676375    0.995652  \n",
      "std      0.935653    1.142693  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    0.000000  \n",
      "50%      0.000000    1.000000  \n",
      "75%      1.000000    2.000000  \n",
      "max      3.000000    4.000000  \n"
     ]
    }
   ],
   "source": [
    "# silient downcasting and warnnings \n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "data_set = pd.read_csv('heart_disease_uci.csv')\n",
    "null_values = data_set.isnull().sum()\n",
    "\n",
    "columns_with_null = null_values[null_values > 0]\n",
    "\n",
    "for column, null_count in columns_with_null.items():\n",
    "    print(f\"{column}: {null_count} null values\")\n",
    "\n",
    "print(data_set.info())\n",
    "print(data_set.describe())\n",
    "\n",
    "\n",
    "# Columns with null values\n",
    "quantitative_columns = ['trestbps', 'chol', 'thalch', 'oldpeak', 'ca']\n",
    "qualitative_columns = ['fbs', 'restecg', 'exang', 'slope', 'thal', 'cp']\n",
    "\n",
    "# 1. Quantitative Columns: Fill missing values with the median\n",
    "data_cleaned = data_set.copy()\n",
    "for col in quantitative_columns:\n",
    "    if data_set[col].isnull().sum() > 0:\n",
    "        median_value = data_set[col].median()\n",
    "        data_cleaned[col] = data_set[col].fillna(median_value)\n",
    "\n",
    "# 2. Qualitative Columns: Fill missing values with the mode\n",
    "for col in qualitative_columns:\n",
    "    if data_set[col].isnull().sum() > 0:\n",
    "        mode_value = data_set[col].mode()[0]\n",
    "        data_cleaned[col] = data_set[col].fillna(mode_value).infer_objects()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No columns with null values.\n"
     ]
    }
   ],
   "source": [
    "null_values = data_cleaned.isnull().sum()\n",
    "\n",
    "columns_with_null = null_values[null_values > 0]\n",
    "if len(columns_with_null) > 0:\n",
    "    print(\"Columns with null values:\")\n",
    "else:\n",
    "    print(\"No columns with null values.\")\n",
    "    \n",
    "for column, null_count in columns_with_null.items():\n",
    "    print(f\"{column}: {null_count} null values\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Two: 1. Descriptive Statistics\n",
    "Perform descriptive statistics analysis for at least two qualitative and two quantitative variables.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Qualitative Variables Analysis ---\n",
      "\n",
      "Descriptive Statistics for sex:\n",
      "sex\n",
      "Male      726\n",
      "Female    194\n",
      "Name: count, dtype: int64\n",
      "Number of unique values: 2\n",
      "Mode: Male\n",
      "Missing values: 0\n",
      "\n",
      "\n",
      "Descriptive Statistics for cp:\n",
      "cp\n",
      "asymptomatic       496\n",
      "non-anginal        204\n",
      "atypical angina    174\n",
      "typical angina      46\n",
      "Name: count, dtype: int64\n",
      "Number of unique values: 4\n",
      "Mode: asymptomatic\n",
      "Missing values: 0\n",
      "\n",
      "\n",
      "--- Quantitative Variables Analysis ---\n",
      "\n",
      "Descriptive Statistics for age:\n",
      "Mean: 53.51\n",
      "Median: 54.00\n",
      "Standard Deviation: 9.42\n",
      "Minimum: 28\n",
      "Maximum: 77\n",
      "Missing values: 0\n",
      "\n",
      "\n",
      "Descriptive Statistics for chol:\n",
      "Mean: 199.13\n",
      "Median: 223.00\n",
      "Standard Deviation: 110.78\n",
      "Minimum: 0.0\n",
      "Maximum: 603.0\n",
      "Missing values: 30\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qualitative_vars = ['sex', 'cp']\n",
    "print(\"\\n--- Qualitative Variables Analysis ---\\n\")\n",
    "\n",
    "for var in qualitative_vars:\n",
    "    print(f\"Descriptive Statistics for {var}:\")\n",
    "    print(data_set[var].value_counts())\n",
    "    print(f\"Number of unique values: {data_set[var].nunique()}\")\n",
    "    print(f\"Mode: {data_set[var].mode()[0]}\")\n",
    "    print(f\"Missing values: {data_set[var].isnull().sum()}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Quantitative Variables Analysis\n",
    "quantitative_vars = ['age', 'chol']\n",
    "print(\"--- Quantitative Variables Analysis ---\\n\")\n",
    "\n",
    "for var in quantitative_vars:\n",
    "    print(f\"Descriptive Statistics for {var}:\")\n",
    "    print(f\"Mean: {data_set[var].mean():.2f}\")\n",
    "    print(f\"Median: {data_set[var].median():.2f}\")\n",
    "    print(f\"Standard Deviation: {data_set[var].std():.2f}\")\n",
    "    print(f\"Minimum: {data_set[var].min()}\")\n",
    "    print(f\"Maximum: {data_set[var].max()}\")\n",
    "    print(f\"Missing values: {data_set[var].isnull().sum()}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Two: 2. Confidence Intervals\n",
    "Calculate the confidence interval for one quantitative variable and the confidence interval for the difference between two groups.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval for Mean Age (95.0%): 52.901 to 54.121\n",
      "Confidence Interval for Difference in Cholesterol Levels (Male - Female) (95.0%): -66.383 to -37.290\n"
     ]
    }
   ],
   "source": [
    "\n",
    "confidence_level = 0.95\n",
    "\n",
    "# Calculate the mean, standard deviation, and standard error\n",
    "age_mean = data_set['age'].mean()\n",
    "age_std = data_set['age'].std()\n",
    "age_n = data_set['age'].count()\n",
    "age_se = age_std / np.sqrt(age_n)\n",
    "\n",
    "# Calculate the confidence interval\n",
    "age_ci = stats.t.interval(confidence_level, df=age_n-1, loc=age_mean, scale=age_se)\n",
    "print(f\"Confidence Interval for Mean Age ({confidence_level*100}%): {age_ci[0]:.3f} to {age_ci[1]:.3f}\")\n",
    "\n",
    "# Confidence Interval for the Difference in Cholesterol Levels between Males and Females\n",
    "chol_male = data_cleaned[data_cleaned['sex'] == 'Male']['chol']\n",
    "chol_female = data_cleaned[data_cleaned['sex'] == 'Female']['chol']\n",
    "\n",
    "# Calculate the means and standard deviations for each group\n",
    "chol_male_mean = chol_male.mean()\n",
    "chol_female_mean = chol_female.mean()\n",
    "chol_male_std = chol_male.std()\n",
    "chol_female_std = chol_female.std()\n",
    "\n",
    "# sample sizes\n",
    "n_male = chol_male.count()\n",
    "n_female = chol_female.count()\n",
    "\n",
    "# Calculate the standard error for the difference between means\n",
    "se_diff = np.sqrt((chol_male_std**2 / n_male) + (chol_female_std**2 / n_female))\n",
    "\n",
    "# Calculate the confidence interval for the difference in means\n",
    "mean_diff = chol_male_mean - chol_female_mean\n",
    "data_cleaned = min(n_male, n_female) - 1\n",
    "ci_diff = stats.t.interval(confidence_level, df=data_cleaned, loc=mean_diff, scale=se_diff)\n",
    "\n",
    "print(f\"Confidence Interval for Difference in Cholesterol Levels (Male - Female) ({confidence_level*100}%): {ci_diff[0]:.3f} to {ci_diff[1]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Two: 3. T-test or ANOVA\n",
    "    \n",
    "Conduct a T-test to check if there is a significant difference between two groups, or Perform an ANOVA to see if all groups have the same mean for a characteristic.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA Results for Cholesterol Levels across Chest Pain Types:\n",
      "F-statistic: 7.5912\n",
      "P-value: 0.0001\n",
      "Result: Significant differences in cholesterol levels across chest pain types (p < 0.05).\n"
     ]
    }
   ],
   "source": [
    "# Separate cholesterol levels by chest pain type (cp)\n",
    "cp_groups = []\n",
    "for cp in data_cleaned['cp'].unique():\n",
    "    # Filter cholesterol values for each unique chest pain type without dropping nulls\n",
    "    chol_values = data_cleaned[data_cleaned['cp'] == cp]['chol']\n",
    "    cp_groups.append(chol_values)\n",
    "    \n",
    "#cp_groups = [data_cleaned[data_cleaned['cp'] == cp]['chol'] for cp in data_cleaned['cp'].unique()]\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_stat, p_value = stats.f_oneway(*cp_groups)\n",
    "\n",
    "# Output the result\n",
    "print(\"ANOVA Results for Cholesterol Levels across Chest Pain Types:\")\n",
    "print(f\"F-statistic: {f_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "# Interpretation\n",
    "if p_value < 0.05:\n",
    "    print(\"Result: Significant differences in cholesterol levels across chest pain types (p < 0.05).\")\n",
    "else:\n",
    "    print(\"Result: No significant differences in cholesterol levels across chest pain types (p â‰¥ 0.05).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Two: 4. Non-Parametric Test\n",
    "Conduct a non-parametric test for the same variable as in Exercise 3 and compare the conclusions with ANOVA results.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal-Wallis Test:\n",
      "Statistic: 12.772943982536457, p-value: 0.005154264553910447\n",
      "Conclusion: There is a statistically significant difference in cholesterol levels among the chest pain types.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Conduct the Kruskal-Wallis test\n",
    "kruskal_stat, kruskal_p_value = kruskal(*cp_groups)\n",
    "\n",
    "# Output the result\n",
    "print(\"Kruskal-Wallis Test:\")\n",
    "print(f\"Statistic: {kruskal_stat}, p-value: {kruskal_p_value}\")\n",
    "\n",
    "# Interpretation based on p-value\n",
    "if kruskal_p_value < 0.05:\n",
    "    print(\"Conclusion: There is a statistically significant difference in cholesterol levels among the chest pain types.\")\n",
    "else:\n",
    "    print(\"Conclusion: No statistically significant difference in cholesterol levels among the chest pain types.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Two: 5. Correlation Analysis\n",
    "Identify the strongest correlations and any statistically insignificant relationships.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Matrix:\n",
      "               age  trestbps      chol    thalch   oldpeak\n",
      "age       1.000000  0.230784 -0.086010 -0.349715  0.233550\n",
      "trestbps  0.230784  1.000000  0.089484 -0.104747  0.161217\n",
      "chol     -0.086010  0.089484  1.000000  0.226047  0.047454\n",
      "thalch   -0.349715 -0.104747  0.226047  1.000000 -0.149401\n",
      "oldpeak   0.233550  0.161217  0.047454 -0.149401  1.000000\n",
      "\n",
      "Strongest Correlations (|correlation| > 0.5):\n",
      "\n",
      "Statistically Insignificant Relationships (p > 0.05):\n",
      "chol and oldpeak: p-value = 0.1504\n",
      "oldpeak and chol: p-value = 0.1504\n"
     ]
    }
   ],
   "source": [
    "quantitative_columns = ['age', 'trestbps', 'chol', 'thalch', 'oldpeak']\n",
    "correlation_matrix = data_cleaned[quantitative_columns].corr()\n",
    "\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "#find the strongest correlations like |correlation| > 0.5\n",
    "\n",
    "strong_correlations = []\n",
    "for col1 in quantitative_columns:\n",
    "    for col2 in quantitative_columns:\n",
    "        if col1 != col2:\n",
    "            correlation = correlation_matrix.loc[col1, col2]\n",
    "            if abs(correlation) > 0.5:\n",
    "                strong_correlations.append((col1, col2, correlation))\n",
    "\n",
    "print(\"\\nStrongest Correlations (|correlation| > 0.5):\")\n",
    "for col1, col2, corr in strong_correlations:\n",
    "    print(f\"{col1} and {col2}: correlation = {corr:.2f}\")\n",
    "\n",
    "\n",
    "#Check statistically insignificant relationships (p > 0.05)\n",
    "insignificant_correlations = []\n",
    "for col1 in quantitative_columns:\n",
    "    for col2 in quantitative_columns:\n",
    "        if col1 != col2:\n",
    "            corr, p_value = pearsonr(data_cleaned[col1].dropna(), data_cleaned[col2].dropna())\n",
    "            if p_value > 0.05:\n",
    "                insignificant_correlations.append((col1, col2, p_value))\n",
    "\n",
    "print(\"\\nStatistically Insignificant Relationships (p > 0.05):\")\n",
    "for col1, col2, p_value in insignificant_correlations:\n",
    "    print(f\"{col1} and {col2}: p-value = {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Two: 6. Multiple Linear Regression\n",
    "Perform a multiple linear regression analysis.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   chol   R-squared:                       0.070\n",
      "Model:                            OLS   Adj. R-squared:                  0.066\n",
      "Method:                 Least Squares   F-statistic:                     17.30\n",
      "Date:                Sat, 26 Oct 2024   Prob (F-statistic):           1.08e-13\n",
      "Time:                        19:37:33   Log-Likelihood:                -5587.8\n",
      "No. Observations:                 920   AIC:                         1.119e+04\n",
      "Df Residuals:                     915   BIC:                         1.121e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -3.3781     40.494     -0.083      0.934     -82.851      76.094\n",
      "age           -0.5604      0.408     -1.372      0.170      -1.362       0.241\n",
      "trestbps       0.6669      0.195      3.422      0.001       0.284       1.049\n",
      "thalch         1.0068      0.148      6.804      0.000       0.716       1.297\n",
      "oldpeak        7.7561      3.409      2.275      0.023       1.065      14.447\n",
      "==============================================================================\n",
      "Omnibus:                       31.741   Durbin-Watson:                   0.865\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               34.196\n",
      "Skew:                          -0.451   Prob(JB):                     3.75e-08\n",
      "Kurtosis:                       3.278   Cond. No.                     2.32e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.32e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Define the target and predictor variables\n",
    "X = data_cleaned[['age', 'trestbps', 'thalch', 'oldpeak']]  # Predictor variables\n",
    "y = data_cleaned['chol']  # Target variable\n",
    "\n",
    "# Drop any rows with missing values in X or y\n",
    "X = X.dropna()\n",
    "y = y.loc[X.index]  # Keep y aligned with the non-null X\n",
    "\n",
    "# Add a constant to X to account for the intercept\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Output the summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.04126403991345806\n",
      "Mean Squared Error: 10766.696003312703\n",
      "Coefficients: [-0.50727281  0.5572145   1.08752555 10.46541804]\n",
      "Intercept: -7.477523001130095\n"
     ]
    }
   ],
   "source": [
    "X = data_cleaned[['age', 'trestbps', 'thalch', 'oldpeak']].dropna()\n",
    "y = data_cleaned['chol'].loc[X.index]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"R-squared:\", r2_score(y_test, y_pred))\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
